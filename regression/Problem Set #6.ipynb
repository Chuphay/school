{
 "metadata": {
  "name": "",
  "signature": "sha256:3934d447e1c6392f7b26402cca8c91154faee941b968f12894557877c0dffc83"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rpy2.ipython"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Problem Set #6"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###8.11"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "s <- \"64.0    4.0    2.0\n",
      "   73.0    4.0    4.0\n",
      "   61.0    4.0    2.0\n",
      "   76.0    4.0    4.0\n",
      "   72.0    6.0    2.0\n",
      "   80.0    6.0    4.0\n",
      "   71.0    6.0    2.0\n",
      "   83.0    6.0    4.0\n",
      "   83.0    8.0    2.0\n",
      "   89.0    8.0    4.0\n",
      "   86.0    8.0    2.0\n",
      "   93.0    8.0    4.0\n",
      "   88.0   10.0    2.0\n",
      "   95.0   10.0    4.0\n",
      "   94.0   10.0    2.0\n",
      "  100.0   10.0    4.0\"\n",
      "x <- strsplit(s,\" +|\\\\n +\")\n",
      "data <-matrix(as.numeric(x[[1]]), ncol=3, byrow =T)\n",
      "fit <-lm(data[,1] ~ data[,2]+data[,3]+data[,2]*data[,3])\n",
      "summary(fit)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\n",
        "Call:\n",
        "lm(formula = data[, 1] ~ data[, 2] + data[, 3] + data[, 2] * \n",
        "    data[, 3])\n",
        "\n",
        "Residuals:\n",
        "   Min     1Q Median     3Q    Max \n",
        "-4.150 -1.488  0.125  1.700  3.700 \n",
        "\n",
        "Coefficients:\n",
        "                    Estimate Std. Error t value Pr(>|t|)    \n",
        "(Intercept)          27.1500     6.4648   4.200  0.00123 ** \n",
        "data[, 2]             5.9250     0.8797   6.735 2.09e-05 ***\n",
        "data[, 3]             7.8750     2.0444   3.852  0.00230 ** \n",
        "data[, 2]:data[, 3]  -0.5000     0.2782  -1.797  0.09749 .  \n",
        "---\n",
        "Signif. codes:  0 \u2018***\u2019 0.001 \u2018**\u2019 0.01 \u2018*\u2019 0.05 \u2018.\u2019 0.1 \u2018 \u2019 1\n",
        "\n",
        "Residual standard error: 2.488 on 12 degrees of freedom\n",
        "Multiple R-squared:  0.9622,\tAdjusted R-squared:  0.9528 \n",
        "F-statistic: 101.9 on 3 and 12 DF,  p-value: 8.379e-09\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>b.)</b> From above, we can see that the  p\u2212value = 0.09749 and therefore the interaction term\n",
      "\n",
      "is not statistically significant at $\\alpha = .05$. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###8.16"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "data_or <- read.table(\"CH01PR19.txt\")\n",
      "data_col <- read.table(\"CH08PR16.txt\")\n",
      "data <- data.frame(data_or,data_col)\n",
      "colnames(data) <- c(\"GPA\",\"ACT\",\"major\")\n",
      "fit <- lm(data$GPA~data$ACT+data$major)\n",
      "summary(fit)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\n",
        "Call:\n",
        "lm(formula = data$GPA ~ data$ACT + data$major)\n",
        "\n",
        "Residuals:\n",
        "     Min       1Q   Median       3Q      Max \n",
        "-2.70304 -0.35574  0.02541  0.45747  1.25037 \n",
        "\n",
        "Coefficients:\n",
        "            Estimate Std. Error t value Pr(>|t|)    \n",
        "(Intercept)  2.19842    0.33886   6.488 2.18e-09 ***\n",
        "data$ACT     0.03789    0.01285   2.949  0.00385 ** \n",
        "data$major  -0.09430    0.11997  -0.786  0.43341    \n",
        "---\n",
        "Signif. codes:  0 \u2018***\u2019 0.001 \u2018**\u2019 0.01 \u2018*\u2019 0.05 \u2018.\u2019 0.1 \u2018 \u2019 1\n",
        "\n",
        "Residual standard error: 0.6241 on 117 degrees of freedom\n",
        "Multiple R-squared:  0.07749,\tAdjusted R-squared:  0.06172 \n",
        "F-statistic: 4.914 on 2 and 117 DF,  p-value: 0.008928\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>a.)</b> and <b>b.)</b>\n",
      "We write the model as\n",
      "\n",
      "$\\hat{Y} = 2.19842 + .03789*ACT \u2212 .09430*major$\n",
      "\n",
      "because the ACT score is never zero, the intercept has no meaning for us, because it is outside the scope of the data.\n",
      "\n",
      "The parameter in front of ACT means that for every unit of increase in the ACT score, the grade point average of the student will increase by a factor of 0.038.\n",
      "\n",
      "The parameter in front of major signifies that if a student had declared a major prior to being accepted, then the grade point average of that student was on average 0.094 less than a student who had not declared a major."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>c.)</b>\n",
      "\n",
      "$H_0$: $\\beta_2$ is equal to zero.  $H_a$: $\\beta_2$ is not equal to zero. My decision rule is that I will reject the null hypothesis if the p-value is less than $\\alpha$\n",
      "\n",
      "The $X_2$ variable has p-value  of 0.43341 which is not significant at the $\\alpha = 0.01$ level. \n",
      " "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "plot(data$ACT*data$major, fit$res)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAADAFBMVEUAAAABAQECAgIDAwMEBAQF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\noGDgoGDgoGDg/D91VbWnO6WqnAAAAABJRU5ErkJggg==\n"
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>d.)</b> There appears to be a positive correlation between the residuals and the interaction term, therefore including the interaction would probably benefit the model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###8.17"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On the surface no, because \n",
      "\n",
      "(8.33) $Y_i = \\beta_0 + \\beta_1 X_{i1} +\\epsilon_i$\n",
      "\n",
      "is not the same as\n",
      "\n",
      "(8.49) $Y_i= \\beta_0 + \\beta_1 X_{i1} +\\beta_3 X_{i1} X_{i2} +\\epsilon_i$\n",
      "\n",
      "However, when we also constrain ourselves with the constraint of interpretability, we know that we must drop complex terms that include simple terms not present in our model. This means that for purposes of interpretability, we would also have to drop $\\beta_3$ from (8.49) and therefore the models would be the same."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###8.34"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>a.)</b>\n",
      "\n",
      "$$Y_i = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\beta_3 X_{3i} + \\epsilon_i$$\n",
      "\n",
      "<b>b.)</b>\n",
      "\n",
      "Commercial Bank: $Y_i = (\\beta_0 + \\beta_2) + \\beta_1 X_{1i} + \\epsilon_i$\n",
      "\n",
      "Mutual Savings:$Y_i = (\\beta_0 + \\beta_3) + \\beta_1 X_{1i} + \\epsilon_i$\n",
      "\n",
      "Savings and Loan:$Y_i = (\\beta_0 - \\beta_2 -\\beta_3) + \\beta_1 X_{1i} + \\epsilon_i$\n",
      "\n",
      "<b>c.)</b>\n",
      "\n",
      "(1) $\\beta_2$ here is the amount the model changes if you are a Commercial Bank.  \n",
      "\n",
      "(2) $\\beta_3$ here is the amount the model changes if you are a Mutual Savings.\n",
      "\n",
      "(3) $\\beta_3+\\beta_2$ here is the amount the model changes if you are a Savings and Loans."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###9.21"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "s <-\"88.0   86.0  110.0  100.0   87.0\n",
      "   80.0   62.0   97.0   99.0  100.0\n",
      "   96.0  110.0  107.0  103.0  103.0\n",
      "   76.0  101.0  117.0   93.0   95.0\n",
      "   80.0  100.0  101.0   95.0   88.0\n",
      "   73.0   78.0   85.0   95.0   84.0\n",
      "   58.0  120.0   77.0   80.0   74.0\n",
      "  116.0  105.0  122.0  116.0  102.0\n",
      "  104.0  112.0  119.0  106.0  105.0\n",
      "   99.0  120.0   89.0  105.0   97.0\n",
      "   64.0   87.0   81.0   90.0   88.0\n",
      "  126.0  133.0  120.0  113.0  108.0\n",
      "   94.0  140.0  121.0   96.0   89.0\n",
      "   71.0   84.0  113.0   98.0   78.0\n",
      "  111.0  106.0  102.0  109.0  109.0\n",
      "  109.0  109.0  129.0  102.0  108.0\n",
      "  100.0  104.0   83.0  100.0  102.0\n",
      "  127.0  150.0  118.0  107.0  110.0\n",
      "   99.0   98.0  125.0  108.0   95.0\n",
      "   82.0  120.0   94.0   95.0   90.0\n",
      "   67.0   74.0  121.0   91.0   85.0\n",
      "  109.0   96.0  114.0  114.0  103.0\n",
      "   78.0  104.0   73.0   93.0   80.0\n",
      "  115.0   94.0  121.0  115.0  104.0\n",
      "   83.0   91.0  129.0   97.0   83.0\"\n",
      "x <- matrix(as.numeric(strsplit(s,\" +|\\\\n +\")[[1]]), ncol= 5, byrow = T)\n",
      "fit <- lm(x[,1] ~ x[,2]+x[,3]+x[,4]+x[,5])\n",
      "library(\"MASS\")\n",
      "stepAIC(fit)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "Start:  AIC=74.95\n",
        "x[, 1] ~ x[, 2] + x[, 3] + x[, 4] + x[, 5]\n",
        "\n",
        "         Df Sum of Sq     RSS     AIC\n",
        "- x[, 3]  1     12.22  348.20  73.847\n",
        "<none>                 335.98  74.954\n",
        "- x[, 5]  1    260.74  596.72  87.314\n",
        "- x[, 2]  1    759.83 1095.81 102.509\n",
        "- x[, 4]  1   1064.15 1400.13 108.636\n",
        "\n",
        "Step:  AIC=73.85\n",
        "x[, 1] ~ x[, 2] + x[, 4] + x[, 5]\n",
        "\n",
        "         Df Sum of Sq     RSS     AIC\n",
        "<none>                 348.20  73.847\n",
        "- x[, 5]  1    258.46  606.66  85.727\n",
        "- x[, 2]  1    763.12 1111.31 100.861\n",
        "- x[, 4]  1   1324.39 1672.59 111.081\n",
        "\n",
        "Call:\n",
        "lm(formula = x[, 1] ~ x[, 2] + x[, 4] + x[, 5])\n",
        "\n",
        "Coefficients:\n",
        "(Intercept)       x[, 2]       x[, 4]       x[, 5]  \n",
        "  -124.2000       0.2963       1.3570       0.5174  \n",
        "\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unfortunately, I can't seem to get PRESS to work in R. Step AIC tells me that we should not use $X_2$, therefore, I have"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "summary(aov(x[,1] ~ x[,2]+x[,4]+x[,5]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "            Df Sum Sq Mean Sq F value   Pr(>F)    \n",
        "x[, 2]       1   2396    2396  144.50 7.05e-11 ***\n",
        "x[, 4]       1   6051    6051  364.97 9.36e-15 ***\n",
        "x[, 5]       1    258     258   15.59 0.000735 ***\n",
        "Residuals   21    348      17                     \n",
        "---\n",
        "Signif. codes:  0 \u2018***\u2019 0.001 \u2018**\u2019 0.01 \u2018*\u2019 0.05 \u2018.\u2019 0.1 \u2018 \u2019 1\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###10.9 (not part f)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "s <- \"64.0    4.0    2.0\n",
      "   73.0    4.0    4.0\n",
      "   61.0    4.0    2.0\n",
      "   76.0    4.0    4.0\n",
      "   72.0    6.0    2.0\n",
      "   80.0    6.0    4.0\n",
      "   71.0    6.0    2.0\n",
      "   83.0    6.0    4.0\n",
      "   83.0    8.0    2.0\n",
      "   89.0    8.0    4.0\n",
      "   86.0    8.0    2.0\n",
      "   93.0    8.0    4.0\n",
      "   88.0   10.0    2.0\n",
      "   95.0   10.0    4.0\n",
      "   94.0   10.0    2.0\n",
      "  100.0   10.0    4.0\"\n",
      "x <- strsplit(s,\" +|\\\\n +\")\n",
      "data <-matrix(as.numeric(x[[1]]), ncol=3, byrow =T)\n",
      "fit <-lm(data[,1] ~ data[,2]+data[,3]+data[,2]*data[,3])\n",
      "summary(fit)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\n",
        "Call:\n",
        "lm(formula = data[, 1] ~ data[, 2] + data[, 3] + data[, 2] * \n",
        "    data[, 3])\n",
        "\n",
        "Residuals:\n",
        "   Min     1Q Median     3Q    Max \n",
        "-4.150 -1.488  0.125  1.700  3.700 \n",
        "\n",
        "Coefficients:\n",
        "                    Estimate Std. Error t value Pr(>|t|)    \n",
        "(Intercept)          27.1500     6.4648   4.200  0.00123 ** \n",
        "data[, 2]             5.9250     0.8797   6.735 2.09e-05 ***\n",
        "data[, 3]             7.8750     2.0444   3.852  0.00230 ** \n",
        "data[, 2]:data[, 3]  -0.5000     0.2782  -1.797  0.09749 .  \n",
        "---\n",
        "Signif. codes:  0 \u2018***\u2019 0.001 \u2018**\u2019 0.01 \u2018*\u2019 0.05 \u2018.\u2019 0.1 \u2018 \u2019 1\n",
        "\n",
        "Residual standard error: 2.488 on 12 degrees of freedom\n",
        "Multiple R-squared:  0.9622,\tAdjusted R-squared:  0.9528 \n",
        "F-statistic: 101.9 on 3 and 12 DF,  p-value: 8.379e-09\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "stu.del.res <- studres(fit)\n",
      "cat(abs(stu.del.res) ,\"\\n\")\n",
      "alpha = 0.01\n",
      "qt(1-alpha/3,12)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "0.6821342 0.6567984 0.7846789 0.8106415 0.1881059 0.955496 0.6154781 0.3355786 0.2932796 0.4420852 1.744814 1.325896 2.4692 1.522964 0.915963 1.051375 \n",
        "[1] 3.27295\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>a.)</b>Because all the studentized residuals are less than 3.27, we conclude that there are no outliers.\n",
      "\n",
      "<b>b.)</b>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "X <- matrix(c(rep(1,16), data[,2],data[,3]), ncol = 3)\n",
      "hatMatrix <- t(X)%*%(solve())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n",
        "[1,]    1    1    1    1    1    1    1    1    1     1     1     1     1     1\n",
        "[2,]    4    4    4    4    6    6    6    6    8     8     8     8    10    10\n",
        "[3,]    2    4    2    4    2    4    2    4    2     4     2     4     2     4\n",
        "     [,15] [,16]\n",
        "[1,]     1     1\n",
        "[2,]    10    10\n",
        "[3,]     2     4\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}