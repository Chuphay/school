{
 "metadata": {
  "name": "",
  "signature": "sha256:cb339179687c5e3b64489961e5e89fe81a00cdb829be10c9b40b6d36e4a6d4ac"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Graduate students are required to complete a research or design project in AI on a topic to be chosen in consultation with me. A written report on the project (minimum 2,500 words) and a brief oral presentation summarizing the same is expected at the end of the term. An ideal project should be one that demonstrates some creativity, attempts to answer some interesting research question(s), or offers an interesting AI solution to a problem of practical interest."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = \"\"\"\n",
      "\"\"\"\n",
      "len(a.split())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<u>Creativity</u>\n",
      "\n",
      "My project demonstrates creativity. I created an atificial neural network from scratch, implementing the details in C. While originally I had bold plans for my Artificial Neural Network, I was crushed by the daunting task, both because of the simple fact that the algorithms involved are highly complex and difficult to understand, but also because I chose to implement the program in C, a language that I have exposure to, but is also not my most comfortable language. \n",
      "\n",
      "My original plan had been to make my artificial Neural network be able to learn how to calculate floating point additions. On the surface, perhaps, this seems like a trivial task, as any modern computer can do floating point calculations. But in fact, this is quite an interesting and creative project for a nueral network to accomplish. As we all know, computers work in a world of ones and zeroes. Floating point calculations by their natures truncate, or approxiamte their answers. On top of that, as we will see in this paper, most beginning applications of Artificial Neural networks concentrate on simple boolean functions, and I thought it would have been interesting to try and up the game a bit. However, as we will also see, I couldn't do that and had to eventually drop back down to the simple boolean functions.\n",
      "\n",
      "The second reason why the floating point calculation is cool, besides for the fact that by their natures ANNs simply output a string of ones and zeros, is because the ANN is truelly learning how to do these calculations. This is like teaching a child how to multiply, but not only teaching him or her how to multiply single digit numbers, but arbitrary floating point numbers (actually in the system I had originally conceived, there still would have been limits on exactly how large the numbers could be). The way you teach a child to multiply is basically the same way you teach an ANN: practice, practice, practice.\n",
      "\n",
      "<u>Interesting Research Questions</u>\n",
      "\n",
      "(maybe this whole section is best at the very end)\n",
      "\n",
      "Unfurtunately the timing in the quarter system does not allow us to fully dive into a project. I would approximate that I spent something like 5 weeks programming the basic algorithms. Now that this is done, there are many questions that can be asked. \n",
      "\n",
      "Questions of topology. (at some point we should introduce what an ANN is)\n",
      "\n",
      "Questions of learning methods: one exampl at a time, batch, sleep, etc.\n",
      "\n",
      "Questions of memory: how many rules can an ANN of a certain topology handle. As one of my papers stated. For simple boolean, you don't need a hidden layer. For more complicated boolean operators, you will need to have a hidden layer. One hidden layer also works for addition. However, to multiply you will need to have two hidden layers. But on top of this is the memory we are already familiar with, where we can put information into short term memory for later and fast retrieval.\n",
      "\n",
      "chaining inputs and outputs so that's it can handle digits greater than one byte. I haven't figured out how to do this yet.\n",
      "\n",
      "\n",
      "sigmoid function dopeness. you have to do discrete calculus rather than normal calculus. It was easiest to implentmeant this as floating point, so for expediances sake I have not worked on this further. \n",
      "\n",
      "\n",
      "<u>C versus Python</u>\n",
      "\n",
      "C is an interesting choice because I can now, and as we will see in the future, I can get very close to the machine in order to get fast performance using a minimum of space. I did not choose Python because I wanted to implement a really efficient system. In retrospect this was probably a mistake. Given the complexity of the task, Python would have been a better choice for at least two reasons. One, Python has a way of making the complex seem, if not trivial, at least tackleble. Two, because of the aforementioned complexity, I was not actually able to implement the program in a clean and precise way, and in fact had to not even think about garbage collection and other issues of equal or perhaps more importance, as I will explain in a different section\n",
      "\n",
      "<u>description of an ANN</u>\n",
      "\n",
      "Artificial Neural Networks or ANNs is an old subfield of Arificial Intelligence research that has recently been resurgent. ANNs attempt to mimic the actual biological mechanisms of a brain. It began in 1943 when Warren McCulloch and Walter Pitts published a paper on them. The human brain is made up of billions of nuerons. Neurons are connected to each other by synapses. Each neuron has hundreds if not thousands of synapses as inputs and thence their output is also connected to thousands of synapses. And in theory, the neuron fires when certain stimuli from the various inputs reaches a certain threshold. The computer model tries to copy this behavior. Every neuron will have a certain number of inputs, and if a certain criterion is reached, then the neuron will fire and send its output to other neurons in the net. \n",
      "\n",
      "Rather than talking about all the steps necessary to create an ANN from the beginning. I am going to walk you hrough all the steps and design decisions that I made while implementing my Neural network. First, I will talk about simple perceptrons (I believe that's what they are called) and then..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<u>Walkthrough of my code</u>\n",
      "\n",
      "<u>First Version</u>\n",
      "\n",
      "First up, really before anything else is to talk about the good things about C. The really nice thing is how close it lets me get to the machine, and I actually operate at the individual level of bits and bytes. Unfourtunately, or really this is just the way that C is made, I can actually only operate at the level of Bytes. In order to manipulate the individual bits, I have to use 'masks'. Here below is a little procedure to ptrint the individual bits in a byte."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```\n",
      "#define BYTE 8\n",
      "\n",
      "void print_byte(char a){\n",
      "  int i;\n",
      "  for(i = 0; i < BYTE; i++) {\n",
      "      printf(\"%d\", !!((a << i) & 128));\n",
      "  }\n",
      "  printf(\"\\n\");\n",
      "}\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From the get go, it should be pointed out that since we are going to consentrate our efforts on one byte at a time, we will be restricetd to positive numbers less than 256. To deal with bigger numbers we will have to do some type of chaining, I have not implemented this yet. \n",
      "\n",
      "My first efforts were directed towards the earliest research on ANNs and simply trying to express simple boolean functions like AND and OR. While later on, we wish to have the weights of the synapses vary according to their importance in a learned way, here, I was satisfied with hard-wiring the correct behaviour.\n",
      "\n",
      "Let's take a close look at how an AND perceptron would behave. There are two binary inputs into the perceptron, plus there is an ever present bias unit. This bias unit is sort of like a door or a gate, and only when the added weight of all the inputs bypass the weight of the door, does the perceptron fire. We are here assuming a hard cut-off (I will talk about this a little more momentarily). The bias unit is always set to one.\n",
      "\n",
      "$$if ~~~ \\sum {inputs * weights } \\ge 0 ~~~ then ~~FIRE!$$\n",
      "\n",
      "With two inputs and one bias unit, we need to have three weights. here are the weights that will make an AND perceptron work: 2 , 2, -3. Let's take a look at how that works. \n",
      "\n",
      "If both inputs are zero, then only the bias unit will contribute, and will contribute $0*2+0*2+1*(-3) = -3$ and therefore the perceptron will not fire. If the first input is a one, but the second input is zero, then the total contribution is $1*2+0*2+1*(-3)= -1$ and again the perceptron will not fire. If the first input is zero and the second input is one, the situation is almost exactly the same. Finally if both inputs are one we have  $1*2+1*2+1*(-3) = 1$ and finally the perceptron will fire, matching the exact performance of an AND gate.\n",
      "\n",
      "If you have never done so, I recommend trying to figure out the weights for an OR perceptron yourself.\n",
      "\n",
      "If you try to make the weghts for an XOR gate, you will quickly find that it is impossible. And that you will need to chain several perceptrons together. Before getting to this, however, I want to discuss my implementation of the AND gate in C, as I found that at every step in this journey led to decisions that implications for the life of the project.\n",
      "\n",
      "Obviously, in the beginning, and having played with someone else's python ANN. I was expecting that I could have arbitrary topologies or architectures. But my abilities with C would not allow that to happen.\n",
      "\n",
      "At this point in the project, I was still hoping to be able to do floating point arithmetic, so I needed to train my network to accept input much larger than just two bits plus a bias unit. At the time I hadn't set in stone that this would be my final architecture, but as I progressed, I realized that I would need to make decisions that would... and this was a decision that I made that stuck. What I decided for this is that I would accept a byte for each input and I would accept a final control byte, which would operate as my bias unit, but could be used in the future for some extra flexibility (I have not been able to take advantage of this.). I also decide to have only one byteo for the output (I now regret this, and would have much preferred haveing two bytes of output). This means that my perceptron would accept 24 bits of information and would output 8 bits. This makes for a total of 192 weights internally in each neuron or perceptron.\n",
      "\n",
      "Before dealing with that, we really must talk about the hard or soft squashing function. There are a few standard models. In the above example we used a hard squahing decision thing. But usually something with a softer edge has an advantage. The most common choice is the sigmoid or logistic function. I have actually had considerable dealings with this function in the past, but I will not burden the reader with that here and now. The sigmoid function is defined as \n",
      "\n",
      "$$\\phi (x) = \\frac 1 {1+ e^{-x}}$$\n",
      "\n",
      "Also, the derivative of this has the extremely simple form: $\\phi * (1 - \\phi)$ which will come into play when we discuss backpropagation.\n",
      "\n",
      "As I was saying we must sum over all the inputs multiplied by their weights. Two Bytes of input plus one byte for the control bit, gives us 24 bits to multiply together. I created a simple function for both of these two procedures:\n",
      "\n",
      "```\n",
      "#define SIZE 3*BYTE\n",
      "\n",
      "double sigmoid(double z){\n",
      "  if(z>4) return 1;\n",
      "  if(z<-4) return 0;\n",
      "\n",
      "  double denom = 1 + exp(-z);\n",
      "  return 1.0/denom;\n",
      "} \n",
      "\n",
      "double dot(double *a, double *b){\n",
      "  double out = 0;\n",
      "  int i;\n",
      "  for(i = 0; i < SIZE; i++){\n",
      "    out += a[i]*b[i];\n",
      "  }\n",
      "  return out;\n",
      "} \n",
      "```\n",
      "\n",
      "Setting up the AND neuron was fairly strightforward. The only crucial piece of technology was that I wanted to ensure that the control bit did indeed have a leading one, otherwise it couldn't be used as a bias. I did this witha simple mask:\n",
      "\n",
      "```\n",
      "a = a|128\n",
      "```\n",
      "128 being the byte that has a leading 1 with the rest of the digits zero. I then initialized a matrix:\n",
      "```\n",
      "double theta[BYTE][SIZE] = {};\n",
      "```\n",
      "and intitialized it in the obvious way (i.e. exactly as above for single bits, but now utilizing a whole byte. Then, I combined the control bytes and the two input bytes into one array:\n",
      "```\n",
      "  double input[SIZE];\n",
      "\n",
      "  int i;\n",
      "  for(i = 0; i < BYTE; i++){\n",
      "    input[i] = !!((a << i) & 128);\n",
      "    input[i+BYTE] = !!((b << i) & 128);\n",
      "    input[i+2*BYTE] = !!((c << i) & 128);\n",
      "  }\n",
      "```\n",
      "Finally, I was able to run this through the sigmoid function:\n",
      "\n",
      "```\n",
      " char out = 0;\n",
      "  for (i = 0 ; i< BYTE; i++){\n",
      "    double temp;  \n",
      "    temp = sigmoid(dot((double *)input, theta[i]));\n",
      "\n",
      "    if(temp>0.5){\n",
      "      out = out|(1<<(BYTE-i-1));\n",
      "    }\n",
      "  }\n",
      "\n",
      "  return out ;\n",
      "```  \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<u>Second Version</u>\n",
      "\n",
      "I knew from before I had even started that hard wiring the code was not learning. I just wanted to make sure that everything was working correctly. The next step was to obviously have a neuron that could accept arbitrary weights as inputs along with the normal inputs and control bits. This is what the definition of the procedure looked like:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```\n",
      "char neuron(char a, char b, char c, double **theta);\n",
      "\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Where we keep it much like in the first version. Char a is simply the control bit we were talking about earlier. It is here for future flexibility, and so basically any char is okay, because again I will use an or command with 128 to make sure that the first bit is set to 1. We use this one as the bias. A good way to think of this bias is like an electrical ground. Char b and char c are the normal inputs that will be combined in someway, and as should be obvious from the declaration, one single char will be returned from this procedure. The internal guts are pretty much the same, but rather than having the weights hard-wired, we now accept a two dimensional matrix, which we call theta. Keep in mind that this two dimensional matrix has dimensions eight by twenty-four.\n",
      "\n",
      "Now that I had my neurons ready, it was time to start chaining them together to form a net. This was also where I started to have some intense problems with my design and my limited abilities to code in C. In doing this, two problems became apparent. I resolved these problems separetly over the course of weeks, so I will talk about these problems seperately, but I should remind you that I had both problems at the same time and fundamentally, these problems are intertwined.\n",
      "\n",
      "\n",
      "<u>The net </u>\n",
      "\n",
      "The main question, was how was I going to chain individual neurons together. I started off with this code:\n",
      "\n",
      "```\n",
      "typedef struct net{\n",
      "  int number;  \n",
      "  int length;\n",
      "  int *layers;\n",
      "  double *theta;\n",
      "} net;\n",
      "\n",
      "net *make_net(int number, int length, int *layers){\n",
      "\n",
      "  double *theta = malloc(SIZE*BYTE*sizeof(double));\n",
      "  net *out = malloc(sizeof(net));\n",
      "  \n",
      "  out->number = number\n",
      "  out->length = length;\n",
      "  out->layers = layers;\n",
      "  out->theta = theta;\n",
      "  return out;\n",
      "} \n",
      "\n",
      "void free_net(net *x){\n",
      "  //I never had the chance to implement this\n",
      "}\n",
      "```\n",
      "\n",
      "With a typical invocation looking like \n",
      "\n",
      "```\n",
      "  int layers[3] = {3,2,1};\n",
      "  net *my_net = make_net(6, 3,layers);\n",
      "  free_net(my_net);\n",
      "``` \n",
      "\n",
      "I added in some redundenc to the program. At the time I was bouncing between two representations. One used the length of the network, in this example, the length is three. The other representation was interested in the number of neurons in the net, in this example there are 6 (or is itonly 3?). Obviously, these are dependent on each other, and with the help of the array layers, you can figure one quantity from the other. Truthfully length (or size) is reduntant, but it just seems easier to pass this extra information. In a future version, I will suppress one in the favor of the other, but for now, the extra information is welcome.\n",
      "\n",
      "Looking back with hindsight, I can see that I was definately on the right track, hwever I got befuddled, and I chose a different track. But this was the track that I should have chosen. Two problems should become apparent while looking at this. The first is to look at how I invoked the layers. My topology is a 3X2X1 network. In theory this should be fine, but if you actually think about what my neurons are capable of, i.e. each neuron accepts 2 inputs and outputs one output, that this is topology is not acceptable at the present moment. It needs either fuller specification of exactly how the wiring between the nodes will be accomplished, or the individual neurons themselves will have to be made more flexible. It took me several weeks of playing around before I finally came upon the solution that I would stick with. Because of the shortness of time, I decided I needed to keep the problem as simple as possible, while still keeping all the main ingrediants. What this meant was that I had to limit what my net was going to be able to accomplish. I had to limit my net because I needed to finish this project, so that I could turn it in in time.\n",
      "\n",
      "The way I decided to limit my net, was by making the architecture or topology quite restricted. What I decided was that the only acceptable topology was to be of the form 2X2X2X...X2X1. Here are my original comments when I made this decision:\n",
      "```\n",
      "  //here's what I'm doing from now on\n",
      "  //Im going to assume that the net is of the form\n",
      "  //2X2X2...2X2X1\n",
      "  //this is C\n",
      "  //and I'm no expert. \n",
      "  //And most importantly,\n",
      "  //Let's make sure we can finish this project!!\n",
      "```  \n",
      "\n",
      "This is obviously severly limiting, and I hope that in a future version of this program, I will be able to relax this requirement. However, even with this topology, we should still be able to do some fun experiments with then net, however floating point calculations are not going to be possible, because each floating point number requires at a minimum about 2 bytes of information, and in order to add or multiply, you would therefore need to be able to input about 4 bytes into the net. My net would only accomadate 2 bytes of iinformation, and was thus unsuitable for floating point arithmatic. \n",
      "\n",
      "<u> Three Dimensional Matrices </u>\n",
      "\n",
      "However, at the time the final architecture was not even the most pressing problem. I don't know if you can see it, but there is a bug in my make_net proceudre. The problem is in this line:\n",
      "\n",
      "```\n",
      "double *theta = malloc(SIZE*BYTE*sizeof(double));\n",
      "\n",
      "``` \n",
      "\n",
      "In retrospect, I can see how I could have done this better... but not now. The problem is that each neuron accepts a two dimensional theta matrix in order to calculate its output. Therefore, in a net with, say, 10 neurons, you will need a three dimensional matrix with dimensions 10X32X8. C does not have an efficient way to make three dimensional matrices, and we must program them by hand. Now, there is a good way to do this, a bad way to do this, and the way I did it (which I guess is the ugly way to do it). Let me detail each way.\n",
      "\n",
      "First up is the good way to do it. The way you really should do this is by laying all the values in a single array and then using a smart algorithm or ordering principle to gain access to each element in the array. A typical implentation of this might look like:\n",
      "\n",
      "```\n",
      "int index(int x, int y, int z) {\n",
      "  return x + (y*xSize) + (z*ySize*xSize);\n",
      "}\n",
      "\n",
      "double value = array[index(a, b, c)];\n",
      "```\n",
      "\n",
      "Not only is this the smart way to do this, you can also imagiine that performing operations on this would be fast and efficient. All the memory would be allocated in one big chunk of memory.\n",
      "\n",
      "The bad way to do this would be to actually implement a three dimensional matrix in C, in much the same way that you would do a two dimensional matrix. This would necessitate three seperate calls to malloc, and therefore your data would be spread out all over the RAM, and you would expect slower performance Also because the implementation is more complicated, it would be much easier to introduce subtl bugs into your program.\n",
      "\n",
      "Finally is the way that I implemented it, which is purely an ugly hack that barely gets the job done. Parenthetically, if I ever get a chance to work on this neural net again, this will be the first thing I will want to change. First, what I did was make a new structure to wrap the individual theta matrices:\n",
      "\n",
      "```\n",
      "typedef struct thet{\n",
      "  double **t;\n",
      "} thet;\n",
      "```\n",
      "\n",
      "This also meant that I had to change the definition of my net ever so slightly:\n",
      "\n",
      "```\n",
      "typedef struct net{\n",
      "  int length;\n",
      "  int size;\n",
      "  int *layers;\n",
      "  thet *theta;\n",
      "} net;\n",
      "```\n",
      "Then I made a procedure to initialize a new two dimensional theta:\n",
      "\n",
      "```\n",
      "double **make_theta(){\n",
      "  double **out = malloc(BYTE*sizeof(double *));\n",
      "  int i,j;\n",
      "  for(i = 0; i < BYTE; i++){\n",
      "    out[i] = malloc(SIZE*sizeof(double));\n",
      "    for(j = 0; j < SIZE; j++){\n",
      "      out[i][j] = rand()/((double)RAND_MAX) -0.5;\n",
      "    }\n",
      "  }\n",
      "  return out;\n",
      "}\n",
      "```\n",
      "\n",
      "Let me call attention to the fact that each weight in the theta matrix is a random number between negative one-half and positive one-half. I will talk about this again when I discuss the backpropagation algorithm.\n",
      "\n",
      "Finally, I made a new make_net initializer, using my extremely awkward theta[i].t construction.  \n",
      "\n",
      "```\n",
      "net *make_net(int number, int length, int *layers){\n",
      "  int i;\n",
      "  thet *theta = malloc((number-layers[0])*sizeof(thet *));\n",
      "  \n",
      "  for( i = 0 ; i< (number-layers[0]); i++){\n",
      "    theta[i].t = make_theta();\n",
      "  }\n",
      "\n",
      "  net *out = malloc(sizeof(net));\n",
      "\n",
      "  out->number = number;\n",
      "  out->layers = layers;\n",
      "  out->theta = theta;\n",
      "  out->length = length;\n",
      "  return out;\n",
      "}\n",
      "```\n",
      "\n",
      "One thing that I would like to point out is that the reason we are subtracting layers[0] from the loop is because 2X2X1 architecture is actually composed of two inputs, two hidden neurons, and one neuron and therefore only needs three neurons.\n",
      "\n",
      "Obviously, this was an ugly hack. But it gets the job done, and because I really wanted to finish the project, this was the way I left it.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<u>Backpropagation</u>\n",
      "\n",
      "Now comes the algorithm that makes an artificial Neural network actually function. The question is that with a single perceptron, it is fairly easy to change the weights so that you get the correct behavior. Let's walk through a simple example, and really spell out exactly how we change the weights. for example let's walk through how we would change the wweights for an OR neuron. Let's assume that in the beginning all the theta is set to zero, , i.e., omega = (0,0,0) (we will see shortly that random weights give the best performance). We will also allow our algorithm, on each mistake we will set a learning rate of three, to help make the example really clear. Reiterating, we only make changes to the weights when the error is equal or more than one-half. (on the real algorithm, I change the weights no matter how small the error). to spread the integer three amonst the various weights to give back a good performance. A simple example will help explain this. First, we put in the combination (0,0) expecting zero to come out. With all the weights set to zero, i.e., omega = (0,0,0), the sigmoid function returns one-half. The only possible weight that can be changed is the weight leading from the bias unit, and we must lower the connection, so we use all three weights it to negative three: (-3,0,0). If we were to run the activation again, now the sigmoid function would receive a value of negative one and therefore would output a value closer to zero as we expected. Now imagine we give it the combination (1,0) expecting a one to come out. Unfoortunately the sigmoid function would give the same result as previously, with an answer close to zero. Thus we would change the weights in the positive diurection, for the sake of argument, let say omega = (0,3,0), and now it would output a value above one half, much as we require. Then we give the perceptron the combination (0,1), it again fires a value at one-half, re-shuffling the weights we would expect to get something like (3,3,3). Finally, we check the last combination (1,1) and it outputs close to one, so we accept this and don't change the weights. Finally we come back around to the beginning, with omega equal to (3,3,3) we get an error, and therefore change omega to (0, 3, 3). All the other combinations pass. Doing a further round, we would get (0, 6, 3). One more round would give (0, 6, 6) and finally one last round would give (-3, 6, 6). Which is the stable result from this algorithm. \n",
      "\n",
      "This is all well and good, and this is the way we would train a single perceptron. A couple things that I would like to point out. We saw that everytime we had an error, we changed the weights by a factor of three. This factor is obviously set by the programmer and is called the learning rate. A small learning rate means that the algorithm will take a long time to get to suitable weights, however it will get there eventually. A large learning rate means that sometimes you are not even able to converge upon a sloution, however, if you are able to converge upon a solution, then it will happen rapidly. I have found that adjusting the learning rate can alter the algorithm dramatically.\n",
      "\n",
      "Another thing is that we did what is called batch learning. What we could have done, and which is what I tried to do in the first place, was to get one example, say (0,0) and learn it really, really well before moving on to the next example. If you were to use this type of learning instead you will quickly find that the neuron becomes extremely forgetfull and will usually forget what it learned previously very fast. If however, you use the method above, and feed it all examples at the same time, and change the weights only slightly between different examples, the results will be better, and the perceptron should in theory be able to learn all linear functions.\n",
      "\n",
      "Finally, as I mentioned, the procedure written above is basically a toy procedure, and the real algorithm changes the weights no matter how small the error.\n",
      "\n",
      "And also, the weights are all set to zero. On a real network doing this can often cause the algorithm not to learn anything at all, for reasoins that are not completely clear to me at the present.\n",
      "\n",
      "Now that we know how to train a single neuron, you might think that it would be easy to train a whole network. But if you spend anytime thinking about it at all, you quickly realize, that while it is easy to train the neurons that are cat the output level, where you actually know what the error is, i.e., what should the output be minus what was the output actually is. It is far from obvious what the error is going to be like on the hidden perceptrons. Basically, how do we assign blame in the hidden layers? In fact, many people thought about this for several decades without coming to a conclusion. \n",
      "\n",
      "\n",
      "Finally, in the mid 1970s, Paul J. Werbos hit upon the idea of using directed partial derivatives to assign blame. For the output layers we assign blame much as we would expect, except that we use calculus:\n",
      "\n",
      "$$\\delta = (t_j-a_j)*a_j*(1 - a_j)$$\n",
      "\n",
      "where $t_j$ is the target. What maybe you can see, and is certainly easy to verify, is that weights that are undecided, i.e. have there weights close to zero, which means that the activation through the sigmoid function will be close to 1/2 will have the biggest errors. And weights that are either really positive or really negative will through the sigmoid function give activations that are either close to zero or close to one and will therefore (plug one into the above formula to see) not have much error attached to it. This means that weights that are undecided change most rapidly with this scheme, and that weights that are already either positive or negative will be difficult to move in either direction.\n",
      "\n",
      "While the derivation of the mathematics is outside the scope of this paper, the result is fairly simple. We assign blame, simply by asking how much was the error at the previous layer and multiplying that by the weight of the contribution. Also, because this derivation comes from calculus (and because if you think about it, we are talking about the gradient of the activation) we must also multiply it by the gradiant of the activation. Here's the final equation of how to measure the error:\n",
      "\n",
      "$$\\delta_j = a_j(1 - a_j) \\sum_k \\delta_k \\omega_{kj}$$\n",
      "\n",
      "\n",
      "\t    //\\omega_{ij} <-- \\omega_{ij} + \\eta \\delta_j a_i\n",
      "\t    \n",
      "\t    //where here a_i is the activation from the future\n",
      "\t    //and eta is the learning rate, to be adjusted later"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After we know exactly who contributed what error, it is straightforward to change the weights accordingly. But obviously since I was the one that implemented this algorithm, this is not the way it happened in practice. In my true algortihm, because it really makes the most amount of sense, is that as soon as I discovered an error, I would then go ahead and then change the weights. This seemed appropriate from a programming perspective, because it means that I did not need to have two loops. (one to discover the errors, and another to correct the weights). However, I think mathematically this is a little fishy, but in practice does not seem to cause much harm.\n",
      "\n",
      "Before showing off the code that implemented this backpropagation algorithm, I want to briefly mention that my design decision to limit the architecture to simple chains of the for 2X2X...X2X1 really paid off in this algorithm beacuse I only had three cases to consider. The absolute last output layer, the layer that came right before the output layer, and all the other layers. This made my life much simpler. Without further ado:\n",
      "\n",
      "```\n",
      "void train(char a, char b, char c, char out, net *x, int epochs){\n",
      "\n",
      "  double RATE = 0.5; //learning rate\n",
      "\n",
      "  double storage[x->size - 2][BYTE]; //activation storage, for later calculation\n",
      "\n",
      "  double input_storage[x->size -2][SIZE]; //input storage, from layer to layer\n",
      "\n",
      "  a = a|128; //usual bitmasking\n",
      "\n",
      "  double *input = make_input(a,b,c); \n",
      "  //here I call an outside function, that turns the three characters\n",
      "  //into a vector of 24 numbers\n",
      "\n",
      "  //first we feed forward \n",
      "  int i,n;\n",
      "  for(i = 0 ; i < x->length - 2;i++){\n",
      "\n",
      "\tchar b_new = activate_neuron(a,b,c,x->theta[2*i].t);\n",
      "\tc = activate_neuron(a,b,c,x->theta[2*i+1].t);\n",
      "\tb = b_new;\n",
      "\n",
      "\tfor(n=0; n<BYTE; n++){\n",
      "\t  storage[2*i][n] = sigmoid(dot(input,x->theta[2*i].t[n]));;\n",
      "\t  storage[2*i+1][n] = sigmoid(dot(input, x->theta[2*i+1].t[n]));\n",
      "\t}\n",
      "\tinput = make_input(a,b,c);\n",
      "\tfor(n =0 ; n<SIZE; n++){\n",
      "\t  input_storage[i][n] = input[n];\n",
      "\t}\n",
      "  }\n",
      "  //our final output layer\n",
      "  for(n=0; n<BYTE; n++){\n",
      "\tstorage[x->size-3][n] =  sigmoid(dot(input, x->theta[x->size -3].t[n]));\n",
      "  }\n",
      "\n",
      "\n",
      "  //Now we go backwards\n",
      "  for(n = 0; n< epochs ; n++){\n",
      "\t\n",
      "    //here we set up two temporary error arrays\n",
      "    double error1[BYTE];\n",
      "    double error2[BYTE];\n",
      "\n",
      "    for(i=0; i<BYTE; i++){\n",
      "      //first the output layer\n",
      "\t  \n",
      "      error1[i] = (!!((out << i) & 128) - storage[x->size-3][i])*(storage[x->size-3][i])*(1-storage[x->size-3][i]);\n",
      "\t  error2[i] = 0;\n",
      "\n",
      "      int j_here;\n",
      "\t  for(j_here = 0 ; j_here <SIZE ; j_here++){\n",
      "        //now we change the weights  \n",
      "\t    x->theta[x->size -3].t[i][j_here] += RATE*error1[i]*input_storage[x->length - 3][j_here];\n",
      "\t  }\n",
      "    }\n",
      "    \n",
      "\tint j;\n",
      "    for(j =  x->length - 2; j>0; j--){\n",
      "\t  if(x->layers[j+1] == 1){\n",
      "        //for the layer right before the output layer\n",
      "        \n",
      "\t    int m;\n",
      "\t    for(m = 0; m<BYTE; m++){\n",
      "\t      double *activation_top = storage[2*j];\n",
      "\t      double *activation_bottom = storage[2*j + 1];\n",
      "\t      int j_p;\n",
      "\t      for (j_p = 0;j_p< BYTE; j_p ++){ \n",
      "            error1[m] = activation_top[m]*(1 - activation_top[m])*error1[j_p]*(x->theta[x->size -3].t[m][j_p+8]);\n",
      "            error2[m] = activation_bottom[m]*(1 - activation_bottom[m])*error1[j_p]*(x->theta[x->size -3].t[m][j_p+16]);\n",
      "\t      }\n",
      "\t      for(j_p = 0 ; j_p <SIZE ; j_p++){\n",
      "\t        x->theta[x->size - 5].t[m][j_p] += RATE*error1[m]*input_storage[x->length - 5][j_p];\n",
      "\t        x->theta[x->size - 4].t[m][j_p] += RATE*error2[m]*input_storage[x->length - 4][j_p];\n",
      "\t      }\n",
      "\t    }\n",
      "\t  } else if (x->layers[j+1] == 2){\n",
      "        //for all other layers  \n",
      "      \n",
      "\t    int m;\n",
      "\t    for(m = 0; m<BYTE; m++){\n",
      "\t      double *activation_top = storage[2*j];\n",
      "\t      double *activation_bottom = storage[2*j + 1];\n",
      "\t      int j_p;\n",
      "\t      for (j_p = 0;j_p< BYTE; j_p ++){ \n",
      "\t\t    double sum1 = error1[j_p]*(x->theta[2*(j)].t[m][j_p+8]) + error2[j_p]*(x->theta[2*(j)].t[m][j_p+8]);\n",
      "\t\t    double sum2 = error1[j_p]*(x->theta[2*(j)+1].t[m][j_p+16]) + error2[j_p]*(x->theta[2*(j)+1].t[m][j_p+16]);\n",
      "\t\t    \n",
      "            error1[m] = activation_top[m]*(1 - activation_top[m])*sum1;\n",
      "\t\t    error2[m] = activation_bottom[m]*(1 - activation_bottom[m])*sum2;\n",
      "\t      }\n",
      "          for(j_p = 0 ; j_p <SIZE ; j_p++){\n",
      "\t        x->theta[2*(j-1)].t[m][j_p] += RATE*error1[m]*input_storage[2*j][j_p];\n",
      "\t        x->theta[2*(j-1) + 1].t[m][j_p] += RATE*error2[m]*input_storage[2*j + 1][j_p];\n",
      "\t      }\n",
      "\t    }\n",
      "\t  } \n",
      "    }\n",
      "  }\t\t\t\t \t\t\t\t\t  \n",
      "}\n",
      "\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Couple of things to note in this algorithm. One is that I hard-wired the learning rate to be 0.5. In a future version of this program I will definately want to be able to adjust this parameter, so I will have to take this out of the function, and use it as a parameter inputed into the program. Another thing to note is that one of the parameters that one can adjust is the number of epochs. As I was saying earlier, generally we will want to have a small learnig rate and then repeat the learning over several examples. The number of repeated learning is usually called the number of epochs in the artificial neural network community. I do have to say, however, that my implentation is completely messed up right here, because we are not reiterating over many examples, but are instead reiterating over only one single example, which completely defeats the purpose of a small learning rate reiterated over many epochs. However, In the final piece of code that I will show for this paper, I"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}