{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"There are several matrices naturally associated with a graph and its vector spaces. The adjacency matrix $A = A(G) = (a_{ij})$ of a graph $G$ is the $n \\times n$ matrix given by\n",
    "\n",
    "$$a_{ij} = \\begin{cases} 1 ~~ if v_i v_j \\in E(G) \\\\ 0 ~~ otherwise \\end{cases}$$\n",
    "\n",
    "Let $D = (D_{ij})$ be the $n \\times n$ diagonal matrix with $D_{ii} = d(v_i)$, the degree of $v_i$ in G.  The matrix $L = D - A$ is called the <i>combinatorial Laplacian</i> or <i>Kirchhoff matrix</i>. \n",
    "\n",
    "The vertex space $C_0(G)$ of a graph G is the complex vector space of all functions from V(G) into $\\mathbb{C}$. Once again we take $V(G) = \\{v_1, v_2, ... , v_n\\}$, so that dim $C_0(G) = n$,  and we write the elements of  $C_0(G)$ in the form $\\mathbf {x} = \\sum_{i=1}^n x_i v_i$ or $\\mathbf{x} = (x_i)_1^n$; here $x_i$ is the value of $\\bf{x}$ at $v_i$, also called the <i>weight</i> at $v_i$. The space  $C_0(G)$ is given the natural inner prodeuct associated with the basis $(v_i)_1^n$ :   $~~<\\mathbf{ x} , \\mathbf{ y}> = \\sum_{i=1}^n x_i \\bar {y_i}$. \n",
    "\n",
    "\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\n",
    "The adjacency matrix A is real and symmetric, so it is <i>hermition</i>, that is, $<A \\mathbf{x}, \\mathbf{y}> = < \\mathbf{x}, A \\mathbf{y}>$. Hence its <i>numerical range</i>\n",
    "\n",
    "$$V(A) = \\{ <A \\mathbf{x}, \\mathbf{x}> : ~~~||\\mathbf{x}|| = 1 \\}$$\n",
    "\n",
    "is a closed interval of the real line. \n",
    "\n",
    "The <i>distinct</i> eigenvalues of A are real, say $\\mu_1 > \\mu_2 > ... > \\mu_t$, and V(A) is exactly the interval $[\\mu_t , \\mu_1]$ (I need a proof for that) \n",
    "\n",
    "\n",
    "\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"In a graph G, let $d_v$ denote the degree of the vertex $v$. We first define the Laplacian for graphs without loops and multiple edges. To begin, we consider the matrix L,\n",
    "\n",
    "$$L(u,v) = \\begin{cases} \n",
    "                  d_v ~~~if ~~u = v\\\\\n",
    "                  -1 ~~~~if ~~ u \\sim v\\\\\n",
    "                  0 ~~~~otherwise\n",
    "                \\end{cases}\n",
    "              $$\n",
    "              \n",
    "Let T denote the diagonal matrix with the $(v,v)$-th entry having value $d_v$. The Laplacian\n",
    "\n",
    "$$\\mathcal{L}(u,v) = \\begin{cases} \n",
    "        1 ~~~ if ~~ u = v\\\\ \n",
    "        -1/{\\sqrt{d_u d_v}} ~~~~ if ~~ u \\sim v \\\\\n",
    "        0 ~~~~ otherwise \n",
    "        \\end{cases}   $$\n",
    "\n",
    "\n",
    "$$\\rightarrow  \\mathcal{L} = T^{-1/2} L T^{-1/2} $$\n",
    "\n",
    "with the convention $T^{-1}(v,v) = 0$ if $d_v = 0$.\n",
    "\n",
    "\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\n",
    "\n",
    "We say $v$ is an isolated vertex if $d_v = 0$. A graph is said to be non-trivial if it contains at least one edge.\n",
    "\n",
    "When G is k-regular, it is easy to see that\n",
    "\n",
    "$$\\mathcal{L} = \\mathbb{I} - \\frac 1 k A$$\n",
    "\n",
    "Where $A$ is the adjacency matrix\n",
    "\n",
    "$$--------------------------$$\n",
    "\n",
    "$\\mathcal{L} $ can be viewed as an operator in the space of functions $g:V(G) \\rightarrow \\mathbb{R}$ which satisfies\n",
    "\n",
    "$$\\mathcal{L} ~ g(u) = \\frac 1 {\\sqrt{d_u}} \\sum_{\\substack{v\\\\ v \\sim u}} \\left( \\frac {g(u)}{\\sqrt{d_u}} - \\frac {g(v)}{\\sqrt{d_v}} \\right)$$\n",
    "\n",
    "\"\n",
    "\n",
    "We need to define the inner product:\n",
    "\n",
    "$$<f,g> = \\sum_x f(x) g(x)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##QR Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The basis for the QR method for calculating the eigenvalues of A is the fact that an $n \\times n$ real matrix can be written as \n",
    "\n",
    "$$A = QR$$\n",
    "\n",
    "where Q is orthogonal and R is upper triangular. (I'll probably need some of these definitions as well later). The method is efficient for the calculation of all eigenvalues of a matrix.\"\n",
    "\n",
    "\"The construction of Q and R proceeds as follows. Matrices $P_1, P_2, ... , P_{n-1}$ are constructed so that $P_{n-1}P_{n-2}\\cdot \\cdot \\cdot P_2 P_1 A = R$ is upper triangular. These matrices can be chosen as orthogonal matrices and are called <i>householder matrices</i>. If we let \n",
    "\n",
    "$$Q^T = P_{n-1}P_{n-2}\\cdot \\cdot \\cdot P_2 P_1$$\n",
    "\n",
    "then we have $Q^T A = R$\" and therefore $A = QR$ (because of orthogonality or something like that)\n",
    "\n",
    "\"We discuss the construction of the P's presently. First we state how the QR factorization of A is used to find eigenvalues of A. We define sequences of matrices $A_1, A_2, ..., A_m, ...; Q_1, Q_2, ..., Q_m, ... ; R_1, R_2, ..., R_m, ...$ by this process:\n",
    "\n",
    "<b>Step 1.</b> Set $A_1 = A, Q_1 = Q$ and $R_1 = R$\n",
    "\n",
    "<b>Step 2.</b> Set $A_2 = R_{1} Q_{1}$; then factor $A_2$ as $A_2 = Q_2 R_2$ (QR factorization of $A_2$)\n",
    "\n",
    "<b>Step m.</b> Set $A_m = R_{m-1} Q_{m-1}$; then factor $A_m$ as $A_m = Q_m R_m$ (QR factorization of $A_m$)\n",
    "\n",
    "\n",
    "\"Matrix $A_m$ will tend toward a triangular or nearly triangular  form. Thus the eigenvalues will of $A_m$ will be easy to calculate\",i.e., they're just the diagonal entries \". The importance is that if the eigenvalues can be ordered as $|\\lambda_1|>|\\lambda_2|> ... > |\\lambda_n|>0$, then the following is true:\n",
    "\n",
    "As m increases the eigenvalues of $A_m$ approach the eigenvalues of A.\n",
    "\n",
    "The proof of this fact is well beyond the scope of this book.\n",
    "\n",
    "Furthermore, \"If A is symmetric, matrices $A_m$ converge to a diagonal matrix with the eigenvalues on the diagonal\"\n",
    "\n",
    "\"Finally, after we find the eigenvalues of A, the corresponding eigenvectors can be found by solving $(\\lambda \\mathbb{I} - A) X = 0$, subject to some side condition such as $|X| = 1$\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From http://www.math.tamu.edu/~dallen/linear_algebra/chpt6.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The idea in QR factorization is to first find $P_1$ which, when multiplied on the left of A, will produce zeros belos $a_{11}$. That is, we want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P_1 \\left(\\begin{matrix} \n",
    "a_{11} \\ a_{12} \\ ... \\ a_{1n} \\\\\n",
    "a_{21} \\ a_{22} \\ ... \\ a_{2n} \\\\\n",
    "\\vdots \\ ~~~ \\ddots \\ ~~~ \\vdots \\\\\n",
    "a_{n1} \\ a_{n2} \\ ... \\ a_{nn}\\\\\n",
    "\\end{matrix}\\right)\n",
    "=\n",
    " \\left(\\begin{array} \n",
    "\\tilde {a_{11}} \\ ~~ \\tilde {a_{12}} \\ ... \\ \\tilde {a_{1n}} \\\\\n",
    "\\textbf{0} \\ ~~ \\tilde {a_{22}} \\ ... \\ \\tilde {a_{2n}} \\\\\n",
    "\\vdots \\ ~~~~~ \\ddots \\ ~~~~~ \\vdots \\\\\n",
    "\\textbf{0} \\ ~~ \\tilde {a_{n2}} \\ ... \\ \\tilde {a_{nn}}\\\\\n",
    "\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this is done, we find $P_2$ which will produce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$P_2 P_1 A = P_2  \\left(\\begin{matrix} \n",
    "\\tilde {a_{11}} \\ ~~ \\tilde {a_{12}} \\ ... \\ \\tilde {a_{1n}} \\\\\n",
    "\\textbf{0} \\ ~~ \\tilde {a_{22}} \\ ... \\ \\tilde {a_{2n}} \\\\\n",
    "\\vdots \\ ~~~~~ \\ddots \\ ~~~~~ \\vdots \\\\\n",
    "\\textbf{0} \\ ~~ \\tilde {a_{n2}} \\ ... \\ \\tilde {a_{nn}}\\\\\n",
    "\\end{matrix}\\right)=\n",
    " \\left(\\begin{matrix} \n",
    "\\hat {a_{11}} \\ ~ \\hat {a_{12}} ~ \\hat {a_{13}} \\ ... \\ \\hat {a_{1n}} \\\\\n",
    "\\textbf{0} \\ ~ \\hat {a_{22}} ~ \\hat {a_{23}} \\ ... \\ \\hat {a_{2n}} \\\\\n",
    "\\textbf{0} \\ ~~ \\textbf {0} ~~~~~ \\hat {a_{33}}  \\ ... \\ ~~ \\hat {a_{3n}} \\\\\n",
    "\\vdots \\ ~~~~ \\ddots \\ ~~~~~ \\vdots \\\\\n",
    "\\textbf{0} \\ ~~~~~ \\textbf{0} \\ ~~ \\hat {a_{3n}} \\ ... \\ \\hat {a_{nn}}\\\\\n",
    "\\end{matrix}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
