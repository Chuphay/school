{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"A <b>random walk</b> on a graph is precisely what its name says: a walk $X_0 X_2 ...$ obtained in a certain random fashion. In its simplest form, it depends oonly on the graph and nothing else. Starting a simple walk at $X_0$, its next vertex, $X_1$, is chosen at random from among the neighbors of $X_0$, then $X_2$ is a random neighbor of $X_1$, and so on.\n",
    "\n",
    "In fact, this <b>simple random walk</b> on a graph is only a little less general than a reversible finite Markov chain: attaching weights to the edges and allowing loops, every reversible finite Markov chain can be obtained in this way.\n",
    "\n",
    "Finite Markov chains are just random walks on weighted directed graphs, with loops allowed. In view of this, it is not surprising that random walks on graphs are of great importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Markov chains are a powerful tool for forecasting future events. Effective use of Markov chains involves the calculation of high powers of matrices\"\n",
    "\n",
    "Example, Calculate $A^6$, where \n",
    "\n",
    "$$A = \\left( \\begin{matrix} 1 \\ 1 \\\\ -2 \\ 4 \\end{matrix} \\right)$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -601,   665],\n",
       "       [-1330,  1394]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = array([[1,1],[-2,4]])\n",
    "A2 = dot(A,A)\n",
    "A4 = dot(A2,A2)\n",
    "A6 = dot(A4,A2)\n",
    "A6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Calculate $A^6$, but this time given that\n",
    "\n",
    "$$ A = P \\left( \\begin{matrix} 2 \\ 0 \\\\ 0 \\ 3 \\end{matrix} \\right) P^{-1} $$\n",
    "\n",
    "Where \n",
    "\n",
    "$$P = \\left( \\begin{matrix} 1 \\ 1 \\\\ 1 \\ 2 \\end{matrix} \\right) ~~~~~~ \\text{and} ~~~ P^{-1} = \\left( \\begin{matrix} 2 \\ -1 \\\\ -1 \\ 1 \\end{matrix} \\right)$$\n",
    "\n",
    "Thus,\n",
    "\n",
    "$$A^6 = P \\left( \\begin{matrix} 1 \\ 1 \\\\ -2 \\ 4 \\end{matrix} \\right)^6 P^{-1} = \\left( \\begin{matrix} 1 \\ 1 \\\\ 1 \\ 2 \\end{matrix} \\right) \\left( \\begin{matrix} 64 \\ 0 \\\\ 0 \\ 729 \\end{matrix} \\right)\\left( \\begin{matrix} 2 \\ -1 \\\\ -1 \\ 1 \\end{matrix} \\right) = \\left( \\begin{matrix} -601 \\ 665 \\\\ -1330 \\ 1394 \\end{matrix} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Example 2 shows that if a matrix $A$ is similar to a diagonal matrix $D$, then computing $A^n$ is easy.\n",
    "\n",
    "Two questions must be answered:\n",
    "\n",
    "1. Given A, can we find $P$ and $D$\n",
    "\n",
    "2. How are powers of matrices used in Markov chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The objective of MArkov analysis is to calculate the probability that a system will be in a particular state at some future time and to determine the long-run behavior of the system.\n",
    "\n",
    "Let a system $S$ have states $s_1, s_2, ... , s_n$. Suppose we observe $S$ at given times $t_1, t_2, ...,t_m, ...$. A <b>Markov chain</b> is a process in which the empirical probability that $S$ is in a particular state at observation time $t_k$ depends only on which state $S$ is in at time $t_{k-1}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Example 5: Show that if $S$, with transition matrix $M$ (I know I didn't define this), has state vector $s$ at time $t=0$, then the state vector at time $t_4$ is $M^4 s$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"It is important to know when we can write a matrix $A$ as \n",
    "\n",
    "$$A = PDP^{-1}$\n",
    "\n",
    "Where $D$ is a diagonal matrix. To see where $D$ comes from, let us suppose\n",
    "\n",
    "$$A = P \\left( \\begin{matrix} 2 \\ 0 \\\\ 0 \\ 3 \\end{matrix} \\right) P^{-1}$$\n",
    "\n",
    "and that $P$ represents a rotation.\n",
    "\n",
    "Let $X$ be a vector, such that\n",
    "\n",
    "$$P^{-1} X = \\left( \\begin{matrix} 1  \\\\ 0 \\end{matrix} \\right)$$\n",
    "\n",
    "or, in other wordds\n",
    "\n",
    "$$P \\left( \\begin{matrix} 1  \\\\ 0 \\end{matrix} \\right) = X$$\n",
    "\n",
    "Then\n",
    "\n",
    "$$AX = P \\left( \\begin{matrix} 2 \\\\ 0 \\end{matrix} \\right) = 2 P \\left( \\begin{matrix} 1  \\\\ 0 \\end{matrix} \\right) = 2X$$\n",
    "\n",
    "We see that 2 is an eigenvalue of $A$, with eigenvector $X$. Note that we don't know $X$ yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"If a matrix $A$ has an eigenpair $(1, X)$, then $X$ is a <b>fixed vector</b> (or fixed point) of $A$. This concept is important for Markov chains. Some Markov chains have the property that as $ n \\rightarrow \\infty$, $M^n$ begins to look the same:\n",
    "\n",
    "$$M = \\left( \\begin{matrix} 27/99 \\ ~~ 27/99  \\\\ 72/99 \\ ~~ 72/99 \\end{matrix} \\right) ~~~ \\rightarrow  ~~~ M^2 = \\left( \\begin{matrix} 27/99 \\ ~~ 27/99  \\\\ 72/99 \\ ~~ 72/99 \\end{matrix} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"If $M^n \\rightarrow T$ as $n \\rightarrow \\infty$. We say the Markov chain is <b>regular</b>.\n",
    "\n",
    "In a regular Markov chain, for any intitial state vector $s$\n",
    "\n",
    "$$M^ns \\rightarrow Ts$$\n",
    "\n",
    "This means that regardless of initial state, the Markov chain settles into an equilibrium state $E = Ts$.\n",
    "\n",
    "If a Markov chain is regular, then the equilibrium state $E$ is a fixed point of $M$. That is,\n",
    "\n",
    "$$ME = E$$\n",
    "\n",
    "Theorem. A Markov chain is regular if and only if $M$ or some power of $M$, has only positive entries.\n",
    "\n",
    "...for this example: \n",
    "\n",
    "$$E = \\left( \\begin{matrix} 10/17 \\\\ 7/17 \\end{matrix} \\right)$$ \n",
    "\n",
    "which is interpreted to mean that the system, in the long run, is in state 1 for 10/17 of the time and in state 2 7/17 of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Given a matrix $A_{(n \\times n)}$ determine whether $A$ is diagonalizable. If so, find $P$ and $D$ such that\n",
    "\n",
    "$$A=PDP^{-1}$$\n",
    "\n",
    "$$\\rightarrow ~~~~~ AP =PD$$\n",
    "\n",
    "We therefore see that \n",
    "\n",
    "$$AP_1 = d_1P_1, ~~~ AP_2 = d_2P_2, ~~~ ... ~~~ , AP_n = d_nP_n$$\n",
    "\n",
    "where $P_k$ is the vector made of the $k_{th}$ column of $P$ and $d_k$ is the $k_{th}$ diagonal element of $D$. We therfore see that $P$ is the matrix made up of columns which are eigenvectors of $A$, and the diagonal elements of $D$ are the corresponding eigenvalues. Moreover, since $P$ is invertible, the columns are linearly independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Once a matrix has been diagonalized, we may want some easy checks on the diagonal form $D$. Since,\n",
    "\n",
    "$$A = P D P^{-1}$$\n",
    "\n",
    "means that $A$ is similar to $D$, then by previous results on similar matrices, we must have\n",
    "\n",
    "$$\\text{tr} A = \\text{tr} D$$\n",
    "\n",
    "$$\\text{det} A = \\text{det} D$$\n",
    "\n",
    "$$\\text{rank} A = \\text{rank} D$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Symmetric and Hermitian matrices, which arise in many applications, enjoy the property of always being diagonalizable. Also, the set of eigenvectors can always be chosen as orthonormal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
