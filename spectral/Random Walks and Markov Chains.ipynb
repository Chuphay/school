{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Random Walks & Markov Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"A <b>random walk</b> on a graph is precisely what its name says: a walk $X_0 X_2 ...$ obtained in a certain random fashion. In its simplest form, it depends oonly on the graph and nothing else. Starting a simple walk at $X_0$, its next vertex, $X_1$, is chosen at random from among the neighbors of $X_0$, then $X_2$ is a random neighbor of $X_1$, and so on.\n",
    "\n",
    "In fact, this <b>simple random walk</b> on a graph is only a little less general than a reversible finite Markov chain: attaching weights to the edges and allowing loops, every reversible finite Markov chain can be obtained in this way.\n",
    "\n",
    "Finite Markov chains are just random walks on weighted directed graphs, with loops allowed. In view of this, it is not surprising that random walks on graphs are of great importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Markov chains are a powerful tool for forecasting future events. Effective use of Markov chains involves the calculation of high powers of matrices\"\n",
    "\n",
    "Example, Calculate $A^6$, where \n",
    "\n",
    "$$A = \\left( \\begin{matrix} 1 \\ 1 \\\\ -2 \\ 4 \\end{matrix} \\right)$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -601,   665],\n",
       "       [-1330,  1394]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = array([[1,1],[-2,4]])\n",
    "A2 = dot(A,A)\n",
    "A4 = dot(A2,A2)\n",
    "A6 = dot(A4,A2)\n",
    "A6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Calculate $A^6$, but this time given that\n",
    "\n",
    "$$ A = P \\left( \\begin{matrix} 2 \\ 0 \\\\ 0 \\ 3 \\end{matrix} \\right) P^{-1} $$\n",
    "\n",
    "Where \n",
    "\n",
    "$$P = \\left( \\begin{matrix} 1 \\ 1 \\\\ 1 \\ 2 \\end{matrix} \\right) ~~~~~~ \\text{and} ~~~ P^{-1} = \\left( \\begin{matrix} 2 \\ -1 \\\\ -1 \\ 1 \\end{matrix} \\right)$$\n",
    "\n",
    "Thus,\n",
    "\n",
    "$$A^6 = P \\left( \\begin{matrix} 1 \\ 1 \\\\ -2 \\ 4 \\end{matrix} \\right)^6 P^{-1} = \\left( \\begin{matrix} 1 \\ 1 \\\\ 1 \\ 2 \\end{matrix} \\right) \\left( \\begin{matrix} 64 \\ 0 \\\\ 0 \\ 729 \\end{matrix} \\right)\\left( \\begin{matrix} 2 \\ -1 \\\\ -1 \\ 1 \\end{matrix} \\right) = \\left( \\begin{matrix} -601 \\ 665 \\\\ -1330 \\ 1394 \\end{matrix} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Example 2 shows that if a matrix $A$ is similar to a diagonal matrix $D$, then computing $A^n$ is easy.\n",
    "\n",
    "Two questions must be answered:\n",
    "\n",
    "1. Given A, can we find $P$ and $D$\n",
    "\n",
    "2. How are powers of matrices used in Markov chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The objective of MArkov analysis is to calculate the probability that a system will be in a particular state at some future time and to determine the long-run behavior of the system.\n",
    "\n",
    "Let a system $S$ have states $s_1, s_2, ... , s_n$. Suppose we observe $S$ at given times $t_1, t_2, ...,t_m, ...$. A <b>Markov chain</b> is a process in which the empirical probability that $S$ is in a particular state at observation time $t_k$ depends only on which state $S$ is in at time $t_{k-1}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Example 5: Show that if $S$, with transition matrix $M$ (I know I didn't define this), has state vector $s$ at time $t=0$, then the state vector at time $t_4$ is $M^4 s$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"It is important to know when we can write a matrix $A$ as \n",
    "\n",
    "$$A = PDP^{-1}$$\n",
    "\n",
    "Where $D$ is a diagonal matrix. To see where $D$ comes from, let us suppose\n",
    "\n",
    "$$A = P \\left( \\begin{matrix} 2 \\ 0 \\\\ 0 \\ 3 \\end{matrix} \\right) P^{-1}$$\n",
    "\n",
    "and that $P$ represents a rotation.\n",
    "\n",
    "Let $X$ be a vector, such that\n",
    "\n",
    "$$P^{-1} X = \\left( \\begin{matrix} 1  \\\\ 0 \\end{matrix} \\right)$$\n",
    "\n",
    "or, in other wordds\n",
    "\n",
    "$$P \\left( \\begin{matrix} 1  \\\\ 0 \\end{matrix} \\right) = X$$\n",
    "\n",
    "Then\n",
    "\n",
    "$$AX = P \\left( \\begin{matrix} 2 \\\\ 0 \\end{matrix} \\right) = 2 P \\left( \\begin{matrix} 1  \\\\ 0 \\end{matrix} \\right) = 2X$$\n",
    "\n",
    "We see that 2 is an eigenvalue of $A$, with eigenvector $X$. Note that we don't know $X$ yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"If a matrix $A$ has an eigenpair $(1, X)$, then $X$ is a <b>fixed vector</b> (or fixed point) of $A$. This concept is important for Markov chains. Some Markov chains have the property that as $ n \\rightarrow \\infty$, $M^n$ begins to look the same:\n",
    "\n",
    "$$M = \\left( \\begin{matrix} 27/99 \\ ~~ 27/99  \\\\ 72/99 \\ ~~ 72/99 \\end{matrix} \\right) ~~~ \\rightarrow  ~~~ M^2 = \\left( \\begin{matrix} 27/99 \\ ~~ 27/99  \\\\ 72/99 \\ ~~ 72/99 \\end{matrix} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"If $M^n \\rightarrow T$ as $n \\rightarrow \\infty$. We say the Markov chain is <b>regular</b>.\n",
    "\n",
    "In a regular Markov chain, for any intitial state vector $s$\n",
    "\n",
    "$$M^ns \\rightarrow Ts$$\n",
    "\n",
    "This means that regardless of initial state, the Markov chain settles into an equilibrium state $E = Ts$.\n",
    "\n",
    "If a Markov chain is regular, then the equilibrium state $E$ is a fixed point of $M$. That is,\n",
    "\n",
    "$$ME = E$$\n",
    "\n",
    "Theorem. A Markov chain is regular if and only if $M$ or some power of $M$, has only positive entries.\n",
    "\n",
    "...for this example: \n",
    "\n",
    "$$E = \\left( \\begin{matrix} 10/17 \\\\ 7/17 \\end{matrix} \\right)$$ \n",
    "\n",
    "which is interpreted to mean that the system, in the long run, is in state 1 for 10/17 of the time and in state 2 7/17 of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Given a matrix $A_{(n \\times n)}$ determine whether $A$ is diagonalizable. If so, find $P$ and $D$ such that\n",
    "\n",
    "$$A=PDP^{-1}$$\n",
    "\n",
    "$$\\rightarrow ~~~~~ AP =PD$$\n",
    "\n",
    "We therefore see that \n",
    "\n",
    "$$AP_1 = d_1P_1, ~~~ AP_2 = d_2P_2, ~~~ ... ~~~ , AP_n = d_nP_n$$\n",
    "\n",
    "where $P_k$ is the vector made of the $k_{th}$ column of $P$ and $d_k$ is the $k_{th}$ diagonal element of $D$. We therfore see that $P$ is the matrix made up of columns which are eigenvectors of $A$, and the diagonal elements of $D$ are the corresponding eigenvalues. Moreover, since $P$ is invertible, the columns are linearly independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Once a matrix has been diagonalized, we may want some easy checks on the diagonal form $D$. Since,\n",
    "\n",
    "$$A = P D P^{-1}$$\n",
    "\n",
    "means that $A$ is similar to $D$, then by previous results on similar matrices, we must have\n",
    "\n",
    "$$\\text{tr} A = \\text{tr} D$$\n",
    "\n",
    "$$\\text{det} A = \\text{det} D$$\n",
    "\n",
    "$$\\text{rank} A = \\text{rank} D$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Symmetric and Hermitian matrices, which arise in many applications, enjoy the property of always being diagonalizable. Also, the set of eigenvectors can always be chosen as orthonormal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##The Important Point\n",
    "\n",
    "Is that as we can see we are looking for an eigenpair with eigenvalue 1. That's what we mean here:\n",
    "\n",
    "\n",
    "$$ME = E$$\n",
    "\n",
    "So let's try that out a bit to see if we can get what we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 27.,  72.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = array([[27/99,27/99],[72/99,72/99]])\n",
    "val, vec = eig(M)\n",
    "v = vec[:,1]\n",
    "99*v/(v[0] + v[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expected.\n",
    "\n",
    "And to tie this into random walks, we will have to expicitly do a random walk.\n",
    "\n",
    "This is from http://www.econ.brown.edu/students/takeshi_suzuki/math_camp_2011/la3-2011.pdf\n",
    "\n",
    "Assume $k$ states of the world, which we label $1, 2, . . . , k$. Let the probability that we move to\n",
    "state $j$ from state $i$ $p_{ij}$ , and call it the transition probability. Then the transition probability\n",
    "matrix of the Markov chain is the matrix\n",
    "\n",
    "\n",
    "$$P =\\left( \\begin{matrix} p_{11} \\  . . . \\  p_{1k} \\\\ \\vdots \\\\p{k1}  \\ ...\\ p_{kk} \\end{matrix} \\right)$$\n",
    "\n",
    "Notice that the rows are the current state, and the columns are the states into which we can move.\n",
    "Also notice that the rows of the transition probability matrix must add up to one (otherwise the\n",
    "system would have positive probability of moving into an undefined state).\n",
    "Example: Say that there are three states of the world: rainy, overcast, and sunny. Let state 1\n",
    "be sunny, 2 be overcast, and 3 be rainy. Consider the transition probability matrix\n",
    "\n",
    "$$P = \\left( \\begin{matrix} 0.8 ~ \\ 0.1 ~ \\ 0.1 \\\\ 0.3 \\ ~ 0.2 \\ ~ 0.5 \\\\ 0.2 ~ \\  0.6 ~ \\ 0.2   \\end{matrix} \\right)$$\n",
    "\n",
    "\n",
    "For example, if it is sunny, the probability it remains sunnny is .8. Also, if it is rainy, the probability\n",
    "that it becomes overcast is .6.\n",
    "\n",
    "And now let's do a random walk on this probability tranisition matrix or whatever it's called.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 34.9286,  13.4017,  12.6758])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = array([[0.8, 0.1 , 0.1], [0.3, 0.2, 0.5], [0.2, 0.6,0.2]])\n",
    "\n",
    "#So let's start in state 0, which I guess is sunny, because why not\n",
    "states = [0]\n",
    "\n",
    "from numpy.random import choice\n",
    "\n",
    "steps = 10000\n",
    "for i in range(steps):\n",
    "    states.append(choice(3, p = M[states[i]]))\n",
    "\n",
    "from scipy.stats import itemfreq\n",
    "61*itemfreq(states)[:,1]/steps #multiply by 61, because I know the answer already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.       ,  0.5472136, -0.3472136]),\n",
       " array([[ 0.87179487,  0.81607429,  0.07844683],\n",
       "        [ 0.35897436, -0.43077627, -0.74305903],\n",
       "        [ 0.33333333, -0.38529801,  0.6646122 ]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And now we try with eigenvalues\n",
    "M = array([[0.8, 0.1 , 0.1], [0.3, 0.2, 0.5], [0.2, 0.6,0.2]])\n",
    "eig(M.T) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 34.,  14.,  13.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val, vec = eig(M.T)\n",
    "v = vec[:,0]\n",
    "61*v/sum(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we needed to transpose the matrix, this is actually pretty straightforward, because we are actually looking at $\\mathbf{x} P = \\mathbf{x}$, which is fairly easy to verify. Thus, we simply transpose this equation, to get what we wanted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next question is, can we efficiently find the eigenvector that has eigenvalue 1?\n",
    "\n",
    "We can try and do it with the power method, but in fact, using the row echelon form, or whatever it is called will probably get the job done even faster:\n",
    "\n",
    "because we know the eigenvalue is 1, we only need to solve:\n",
    "\n",
    "$$P^T \\mathbf{y} = \\mathbf{y} ~~~ \\rightarrow ~~~ (P^T - \\mathbf{I}) \\mathbf{y} = \\mathbf{0}$$\n",
    "\n",
    "This is an equation we should be able to solve with gaussian elimination, very efficiently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def row_echelon(L):\n",
    "    n = L.shape[0]\n",
    "    b = array([[float(L[i][j]) for j in range(L.shape[1])] for i in range(n)])\n",
    "    b = around(b,6)  #cutting off at 6 decimal places\n",
    "    for i in reversed(range(b.shape[0])):\n",
    "        if(b[i][i] == 0):\n",
    "            #print(\"woh, zero\")\n",
    "            continue\n",
    "        b[i] = b[i]/b[i][i]\n",
    "        if(i != 0):\n",
    "            for j in range(i):\n",
    "                b[j] = b[j] - b[i]*b[j][i]/b[i][i]       \n",
    "    return b\n",
    "\n",
    "def gaussian_elim(L):\n",
    "    n = L.shape[0]\n",
    "    b = array([[float(L[i][j]) for j in range(L.shape[1])] for i in range(n)]) \n",
    "    for i in range(n):\n",
    "        if(b[i][i] == 0):\n",
    "            for k in range(i+1,n):\n",
    "                if(b[i][k] != 0):\n",
    "                    raise ValueError(\"Yikes!!! Have to do a swap\")\n",
    "            continue        \n",
    "        for j in range(i+1,n):\n",
    "            b[j] = b[j] - b[i]*b[j][i]/b[i][i]  \n",
    "    return around(b,6) #cutting off at 6 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.        , -2.61538462],\n",
       "       [-0.        ,  1.        , -1.07692308],\n",
       "       [ 0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = gaussian_elim(M.T - eye(3))\n",
    "ans = row_echelon(temp)\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, still taking from http://www.econ.brown.edu/students/takeshi_suzuki/math_camp_2011/la3-2011.pdf\n",
    "\n",
    "$$q_1 = 2.615 q_3$$\n",
    "\n",
    "$$q_2 = 1.077 q_3$$\n",
    "\n",
    "$$q_3 = q_3$$\n",
    "\n",
    "Therefore, $\\mathbf{q} = (2.615, 1.077, 1) q_3$ , where $q_3$ can be whatever we want. This will yield, with correct choice of $q_3$ we have \n",
    "\n",
    "$$\\mathbf{q} = (34/61,  14/61,  13/61)$$\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
