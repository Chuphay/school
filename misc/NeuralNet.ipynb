{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From: http://danielfrg.com/blog/2013/07/03/basic-neural-network-python/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from scipy import optimize\n",
      "from __future__ import division\n",
      "\n",
      "class NN_1HL(object):\n",
      "    \n",
      "    def __init__(self, reg_lambda=0, epsilon_init=0.12, hidden_layer_size=25, opti_method='TNC', maxiter=500):\n",
      "        self.reg_lambda = reg_lambda\n",
      "        self.epsilon_init = epsilon_init\n",
      "        self.hidden_layer_size = hidden_layer_size\n",
      "        self.activation_func = self.sigmoid\n",
      "        self.activation_func_prime = self.sigmoid_prime\n",
      "        self.method = opti_method\n",
      "        self.maxiter = maxiter\n",
      "    \n",
      "    def sigmoid(self, z):\n",
      "        return 1 / (1 + np.exp(-z))\n",
      "    \n",
      "    def sigmoid_prime(self, z):\n",
      "        sig = self.sigmoid(z)\n",
      "        return sig * (1 - sig)\n",
      "    \n",
      "    def sumsqr(self, a):\n",
      "        return np.sum(a ** 2)\n",
      "    \n",
      "    def rand_init(self, l_in, l_out):\n",
      "        return np.random.rand(l_out, l_in + 1) * 2 * self.epsilon_init - self.epsilon_init\n",
      "    \n",
      "    def pack_thetas(self, t1, t2):\n",
      "        return np.concatenate((t1.reshape(-1), t2.reshape(-1)))\n",
      "    \n",
      "    def unpack_thetas(self, thetas, input_layer_size, hidden_layer_size, num_labels):\n",
      "        t1_start = 0\n",
      "        t1_end = hidden_layer_size * (input_layer_size + 1)\n",
      "        t1 = thetas[t1_start:t1_end].reshape((hidden_layer_size, input_layer_size + 1))\n",
      "        t2 = thetas[t1_end:].reshape((num_labels, hidden_layer_size + 1))\n",
      "        return t1, t2\n",
      "    \n",
      "    def _forward(self, X, t1, t2):\n",
      "        m = X.shape[0]\n",
      "        ones = None\n",
      "        if len(X.shape) == 1:\n",
      "            ones = np.array(1).reshape(1,)\n",
      "        else:\n",
      "            ones = np.ones(m).reshape(m,1)\n",
      "        \n",
      "        # Input layer\n",
      "        a1 = np.hstack((ones, X))\n",
      "        \n",
      "        # Hidden Layer\n",
      "        z2 = np.dot(t1, a1.T)\n",
      "        a2 = self.activation_func(z2)\n",
      "        a2 = np.hstack((ones, a2.T))\n",
      "        \n",
      "        # Output layer\n",
      "        z3 = np.dot(t2, a2.T)\n",
      "        a3 = self.activation_func(z3)\n",
      "        return a1, z2, a2, z3, a3\n",
      "    \n",
      "    def function(self, thetas, input_layer_size, hidden_layer_size, num_labels, X, y, reg_lambda):\n",
      "        t1, t2 = self.unpack_thetas(thetas, input_layer_size, hidden_layer_size, num_labels)\n",
      "        \n",
      "        m = X.shape[0]\n",
      "        Y = np.eye(num_labels)[y]\n",
      "        \n",
      "        _, _, _, _, h = self._forward(X, t1, t2)\n",
      "        costPositive = -Y * np.log(h).T\n",
      "        costNegative = (1 - Y) * np.log(1 - h).T\n",
      "        cost = costPositive - costNegative\n",
      "        J = np.sum(cost) / m\n",
      "        \n",
      "        if reg_lambda != 0:\n",
      "            t1f = t1[:, 1:]\n",
      "            t2f = t2[:, 1:]\n",
      "            reg = (self.reg_lambda / (2 * m)) * (self.sumsqr(t1f) + self.sumsqr(t2f))\n",
      "            J = J + reg\n",
      "        return J\n",
      "        \n",
      "    def function_prime(self, thetas, input_layer_size, hidden_layer_size, num_labels, X, y, reg_lambda):\n",
      "        t1, t2 = self.unpack_thetas(thetas, input_layer_size, hidden_layer_size, num_labels)\n",
      "        \n",
      "        m = X.shape[0]\n",
      "        t1f = t1[:, 1:]\n",
      "        t2f = t2[:, 1:]\n",
      "        Y = np.eye(num_labels)[y]\n",
      "        \n",
      "        Delta1, Delta2 = 0, 0\n",
      "        for i, row in enumerate(X):\n",
      "            a1, z2, a2, z3, a3 = self._forward(row, t1, t2)\n",
      "            \n",
      "            # Backprop\n",
      "            d3 = a3 - Y[i, :].T\n",
      "            d2 = np.dot(t2f.T, d3) * self.activation_func_prime(z2)\n",
      "            \n",
      "            Delta2 += np.dot(d3[np.newaxis].T, a2[np.newaxis])\n",
      "            Delta1 += np.dot(d2[np.newaxis].T, a1[np.newaxis])\n",
      "            \n",
      "        Theta1_grad = (1 / m) * Delta1\n",
      "        Theta2_grad = (1 / m) * Delta2\n",
      "        \n",
      "        if reg_lambda != 0:\n",
      "            Theta1_grad[:, 1:] = Theta1_grad[:, 1:] + (reg_lambda / m) * t1f\n",
      "            Theta2_grad[:, 1:] = Theta2_grad[:, 1:] + (reg_lambda / m) * t2f\n",
      "        \n",
      "        return self.pack_thetas(Theta1_grad, Theta2_grad)\n",
      "    \n",
      "    def fit(self, X, y):\n",
      "        num_features = X.shape[0]\n",
      "        input_layer_size = X.shape[1]\n",
      "        num_labels = len(set(y))\n",
      "        \n",
      "        theta1_0 = self.rand_init(input_layer_size, self.hidden_layer_size)\n",
      "        theta2_0 = self.rand_init(self.hidden_layer_size, num_labels)\n",
      "        thetas0 = self.pack_thetas(theta1_0, theta2_0)\n",
      "        \n",
      "        options = {'maxiter': self.maxiter}\n",
      "        _res = optimize.minimize(self.function, thetas0, jac=self.function_prime, method=self.method, \n",
      "                                 args=(input_layer_size, self.hidden_layer_size, num_labels, X, y, 0), options=options)\n",
      "        \n",
      "        self.t1, self.t2 = self.unpack_thetas(_res.x, input_layer_size, self.hidden_layer_size, num_labels)\n",
      "    \n",
      "    def predict(self, X):\n",
      "        return self.predict_proba(X).argmax(0)\n",
      "    \n",
      "    def predict_proba(self, X):\n",
      "        _, _, _, _, h = self._forward(X, self.t1, self.t2)\n",
      "        return h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.datasets as datasets\n",
      "from sklearn import cross_validation\n",
      "from sklearn.metrics import accuracy_score\n",
      "iris = datasets.load_iris()\n",
      "X = iris.data\n",
      "y = iris.target\n",
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4)\n",
      "nn = NN_1HL()\n",
      "nn.fit(X_train, y_train)\n",
      "accuracy_score(y_test, nn.predict(X_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:68: RuntimeWarning: divide by zero encountered in log\n",
        "-c:68: RuntimeWarning: invalid value encountered in multiply\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "0.98333333333333328"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nn = NN_1HL()\n",
      "x = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
      "nn.fit(x, ([0,0,0,1]))\n",
      "nn.predict(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "array([0, 0, 0, 1])"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "class NN(object):\n",
      "    def __init__(self, theta = None):\n",
      "        if theta == None:\n",
      "            self.theta = np.random.randn(12).reshape(3,4)\n",
      "        else:\n",
      "            self.theta = theta\n",
      "        #self.memory = np.random.randn(3)    \n",
      "    def sigmoid(self, z):\n",
      "        return 1 / (1 + np.exp(-z))\n",
      "    \n",
      "    def predict(self, X):\n",
      "        ones = None\n",
      "\n",
      "        \n",
      "        if len(X.shape) == 1:\n",
      "            ones = np.array(1).reshape(1,)\n",
      "        else:\n",
      "            ones = np.ones(X.shape[0]).reshape(X.shape[0],1)        \n",
      "        X = np.hstack((ones, X))\n",
      "        #print self.memory\n",
      "        #X = np.hstack((self.memory,X))\n",
      "        #print X\n",
      "        out = self.sigmoid(np.dot(self.theta,X.T))\n",
      "        if len(out.shape)>1:\n",
      "            out = out.mean(axis = 1)\n",
      "        out = out.round()\n",
      "        return out\n",
      "    def fit(self, X, target):\n",
      "        while True:\n",
      "            new_net = NN(self.theta + 1.7*np.random.randn(12).reshape(3,4))\n",
      "            if (new_net.predict(X) == target).all():\n",
      "                break\n",
      "        self.theta = new_net.theta \n",
      "        \n",
      "    def train(self, X_matrix, target_matrix, epochs = 2):\n",
      "        for e in range(epochs):\n",
      "            #print 'epochs: '+ str(e)\n",
      "            for i in range(len(target_matrix)):\n",
      "                self.fit(X_matrix[i],target_matrix[i])\n",
      "        \n",
      "\n",
      "X_matrix = np.array([[0,0,0],[1,0,1],[0,1,0]])\n",
      "zero = NN()\n",
      "z = np.array([[0,0,0],[0,0,0],[0,0,0]])\n",
      "zero.train(X_matrix,z)\n",
      "zero.predict(np.array([1,0,0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 84,
       "text": [
        "array([ 0.,  0.,  0.])"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(1):\n",
      "    nn = NN()\n",
      "    X = np.array([[0,0,1],[1,1,1]])\n",
      "    \n",
      "        \n",
      "    nn.fit(X,np.array([0,0,0]))\n",
      "        \n",
      "    X_matrix = np.array([[[0,0,1],[1,1,1]],\n",
      "                        [[0,0,1],[0,0,1]],\n",
      "                        [[1,1,1],[1,1,0]],\n",
      "                        [[1,0,1],[0,1,0]]])\n",
      "        \n",
      "    tick = np.array([[0,0,1],[0,0,1],[1,1,0],[0,0,0]])\n",
      "    nn.train(X_matrix,tick, epochs = 10)\n",
      "    print nn.predict(X)\n",
      "    print 'here'\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class MemNet(NN):\n",
      "    def __init__(self, theta = None, memory = None):\n",
      "        NN.__init__(self, theta)\n",
      "        if memory == None:\n",
      "            self.memory = np.random.randn(3) \n",
      "        else:\n",
      "            self.memory = memory\n",
      "            \n",
      "    def predict(self, X):\n",
      "        ones = None\n",
      "\n",
      "        \n",
      "        if len(X.shape) == 1:\n",
      "            ones = np.array(1).reshape(1,)\n",
      "        else:\n",
      "            ones = np.ones(X.shape[0]).reshape(X.shape[0],1)        \n",
      "        X = np.hstack((ones, X))\n",
      "        #print self.memory\n",
      "        #X = np.hstack((self.memory,X))\n",
      "        #print X\n",
      "        out = self.sigmoid(np.dot(self.theta,X.T))\n",
      "        if len(out.shape)>1:\n",
      "            out = out.mean(axis = 1)\n",
      "        out = out.round()\n",
      "        return out\n",
      "            \n",
      "click = MemNet(memory = np.array([0,0,0]))         \n",
      "X = np.array([[0,0,1],[0,0,1],[0,0,1],[0,0,1]])\n",
      "z = np.array([[0,0,0],[0,0,1],[0,1,0],[0,1,1]])\n",
      "click.train(X,z)\n",
      "click.predict(np.array([0,0,1]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epochs: 0\n",
        "epochs: 1\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 57,
       "text": [
        "array([ 0.,  1.,  1.])"
       ]
      }
     ],
     "prompt_number": 57
    }
   ],
   "metadata": {}
  }
 ]
}